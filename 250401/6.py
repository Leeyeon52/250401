import joblib
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

# ë°ì´í„° ìƒì„±
X = np.random.rand(500, 3)
y = np.random.randint(0, 2, size=500)

# ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ”¹ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (SVM, Logistic Regression ì„±ëŠ¥ ê°œì„  ê¸°ëŒ€)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ğŸ”¹ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì¶”ê°€)
models = {
    "Logistic Regression": LogisticRegression(C=1.0),
    "Random Forest": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=150, learning_rate=0.05),
    "SVM": SVC(kernel='rbf', C=1.0, gamma='scale')
}

# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    joblib.dump(model, f"{name.replace(' ', '_')}.pkl")  # ëª¨ë¸ ì €ì¥

# ê²°ê³¼ ì¶œë ¥
print("\nğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼ (ìŠ¤ì¼€ì¼ë§ & íŠœë‹ ì ìš©):")
for name, acc in results.items():
    print(f"{name}: {acc:.4f}")

# ìµœì  ëª¨ë¸ ì €ì¥
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
joblib.dump(best_model, "best_model.pkl")

print(f"\nğŸ† ìµœì  ëª¨ë¸: {best_model_name} (ì €ì¥ ì™„ë£Œ)")
